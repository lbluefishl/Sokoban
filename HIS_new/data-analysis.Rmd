---
title: "Study 1 - Sokoban"
author: "Mike"
date: "2025-02-04"
---

```{r, include=FALSE}
if (!requireNamespace("rmarkdown", quietly = TRUE)) {
  stop("This file requires the rmarkdown package to render. Please install it with install.packages('rmarkdown').")
}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(lme4, tidyverse, psych, lmerTest, ggeffects, jsonlite, cluster, MuMIn, emmeans, effectsize, pbkrtest)
```

## Importing Data and Preprocessing

Our raw dataset consists of a file which includes data for each trial. Each participant also completed a survey, which we can match to the trial data with the prolific ID. We first preprocess the data by converting each column into their proper data types.  

```{r warning=FALSE}
raw_data <- fromJSON("fullstudy.combined.json")
raw_survey <- fromJSON("fullstudy.surveys.json")

numeric_cols_data <- c("aha1", "aha2", "aha3", "correctValue", "completedLevel", "completedEarly", "difficultyValue", "durationAfterBreak",
                  "durationBeforeBreak", "durationBreak", "durationToBeatGame", "idleTime",
                  "incorrectValue", "nm1", "nm2", "nm3", "r1b", "r2b", "r3b", "scrollCount",
                  "sessionID", "stuckValue", "e1", "e2", "e3", "f1", "f2", "f3", "mw1", "mw2",
                  "mw3", "pw", "r1", "r2", "r3", "ra")

factor_cols_data <- c("condition", "levelNumber","prolificPID")

numeric_cols_survey <- c("age")

factor_cols_survey <- c("sex", "handedness", "trialOrder", "conditionOrder")

raw_data <- raw_data %>% 
  mutate(
    across(all_of(numeric_cols_data), ~ as.numeric(.)),
    across(all_of(factor_cols_data), ~ as.factor(.)),
    condition = recode(condition,
                       "1" = "No Break",
                       "2" = "Non-HIS",
                       "3" = "HIS"
                       )
  )

raw_survey <- raw_survey %>% 
  mutate(
    across(all_of(numeric_cols_survey), ~ as.numeric(.)),
    across(all_of(factor_cols_survey), ~ as.factor(.)),
    across(c(videoGameHours, smartphoneHours, digitalDeviceHours, shortFormVideoHours), 
           ~ as.numeric(recode(., 
                               "lessThan1" = 1,
                               "1to2" = 2,
                               "2to3" = 3,
                               "3to4" = 4,
                               "5plus" = 5))),
    sokobanFamiliarity = as.numeric(recode(sokobanFamiliarity,
                            "notFamiliar" = 1,
                            "somewhatFamiliar" = 2,
                            "veryFamiliar" = 3
                                           ))
  )
```

## Exclusions
Note that there is not the expected ratio of 3 trials to 1 participant. This is because some individuals either timed out by being idle or did not complete the three practice trials within 10 minutes. Some participants also completed trials multiple times, likely because they refreshed the page or restarted the study. Furthermore, form submissions were sometimes duplicated internally. Some participants' data were also not recorded for some trials, so we decide to remove all of their trials. 

```{r}
problematic_ids <- raw_data %>%
  group_by(prolificPID) %>%
  summarise(row_count = n()) %>%
  filter(row_count != 3) %>%
  pull(prolificPID)

data <- raw_data %>%
  filter(
    !prolificPID %in% problematic_ids,
    prolificPID %in% raw_survey$prolificPID
    )

survey <- raw_survey %>% 
  filter(
    completedAllLevels != 0,
    prolificPID %in% data$prolificPID,
    ) %>% 
  distinct(prolificPID, .keep_all = TRUE)
  
```
Aside from these technical exclusions, we decided to improve the quality of data by removing participants that showed very low engagement during one of their trials. We removed participants who had only one or no move sets before or after the break. We also removed them if they went idle during the break periods (which should only last around 180 seconds plus the time it takes to respond to questions).


```{r}
participants_excluded <- data %>% 
  group_by(prolificPID) %>% 
  filter(
    any(completedLevel == 0 & lengths(afterBreakMovesets) < 2) |
    any(completedLevel == 0 & lengths(beforeBreakMovesets) < 2) |
    any(completedLevel == 0 & durationBreak > 360)
  )

data <- data %>% 
  filter(!prolificPID %in% participants_excluded$prolificPID)
```

## Validity and Reliability of Measures

For each construct, we use each participant's first possible use of the scale during the first trial (since participants could possibly respond to each scale multiple times). This would exclude participants who completed the puzzle early on their first trial and those that are in the no break condition for the first puzzle.   

```{r}
items <- data %>%
  filter(completedEarly == 0, condition != "No Break") %>%      
  left_join(
    survey %>%
      mutate(first_trial = substr(trialOrder, 1, 1)) %>%
      select(prolificPID, first_trial),                                 
    by = "prolificPID"
  ) %>%
  filter(levelNumber == first_trial) %>%                  
  select(starts_with("aha"), starts_with("nm"), starts_with("e"), starts_with("f"), starts_with("mw"), r1b, r2b, r3b, -first_trial) %>% 
  drop_na()

```

We first use confirmatory factor analysis to check for convergent and divergent validity. Important variables include those used as a manipulation check (heightened enjoyment, focused immersion, and mind-wandering, insight experience) and supplemental variables (perceived use of new moves, resources). 

```{r}
fa(items, nfactors = 6, rotate = "oblimin")
```

We assess internal consistency using Cronbach's alpha.

```{r warning = FALSE}

scales <- list(
  insight = items[,1:3],
  new_moves = items[,4:6],
  enjoyment = items[,7:9],
  immersion = items[,10:12],
  mind_wandering = items[,13:15],
  resources = items[,16:18]
)

sapply(scales, function(x) alpha(x)$total$raw_alpha)

```

## General Performance

Completion data for each level
```{r}
completion <- data %>%
  group_by(levelNumber) %>%
  summarise(
    completed_count = sum(completedLevel),              
    percent_completed = mean(completedLevel) * 100,     
    sample_size = n()                                             
  )

completion
```

Completion duration
```{r}
completion_duration <- data %>%
  filter(completedLevel == 1) %>% 
  mutate(
    durationBreak = replace_na(durationBreak, 0),
    totalTime = durationToBeatGame - durationBreak
    ) %>% 
  group_by(levelNumber) %>%
    summarize(duration_to_beat_puzzle = mean(totalTime, na.rm = TRUE))   
              
completion_duration 
```

For the ease of interpretation, rather than referring to the levels using the internal numbers, we can now classify based on their actual difficulties.

```{r}
data <- data %>%
  mutate(levelNumber = recode(levelNumber,
                              `5` = "hard",
                              `7` = "easy",
                              `8` = "medium")) %>%
  rename(level = levelNumber) %>%
  mutate(level = factor(level, levels = c("easy", "medium", "hard")))
```

For participants who did not complete puzzles early, we obtained brief 1-item measures for perceived difficulty and impasse.

```{r}
data %>% 
  group_by(level) %>% 
    summarize(
      average_difficulty = mean(difficultyValue, na.rm = TRUE)     
    )


data %>% 
  group_by(level) %>% 
  summarize(
    average_impasse = mean(stuckValue, na.rm = TRUE)     
  )

```

## Manipulation Checks

We first check whether the non-HIS and HIS condition were different from each other. Here, we average our items for each construct. For resources, we take the difference to get a measure of the changes in resources after taking a break. 

```{r}
manipulation_data <- data %>%
  filter(condition != "No Break") %>% 
  drop_na(f1, f2, f3, nm1, nm2, nm3, e1, e2, e3, mw1, mw2, mw3, r1b, r2b, r3b, r1, r2, r3, ra, pw) %>% 
  mutate(
    focused_immersion = rowMeans(select(., f1, f2, f3)),
    heightened_enjoyment = rowMeans(select(., e1, e2, e3)),
    mind_wandering = rowMeans(select(., mw1, mw2, mw3)),
    perceived_use_of_new_strategies = rowMeans(select(., nm1, nm2, nm3)),
    resources_before = rowMeans(select(., r1b, r2b, r3b)),
    resources_after = rowMeans(select(., r1, r2, r3)),
    resources_difference = resources_after - resources_before
  )


```

Mixed effects models are used here to account for the repeated measures in our experiment (i.e., control for baseline differences among participants). Note that the intercept represents the value of the Non-HIS condition. For parsimony we do not include any control variables. 

Focused immersion
```{r}
fi_lm <- lmer(focused_immersion ~ condition + (1|prolificPID), data = manipulation_data)
summary(fi_lm) 
confint(fi_lm, method = "Wald")
```

Heightened enjoyment
```{r}
he_lm <- lmer(heightened_enjoyment ~ condition + (1|prolificPID), data = manipulation_data)
summary(he_lm) 
confint(he_lm, method = "Wald")
```

Mind-wandering
```{r}
mw_lm <- lmer(mind_wandering ~ condition + (1|prolificPID), data = manipulation_data)
summary(mw_lm) 
confint(mw_lm, method = "Wald")
```

Active work on the puzzle during the break
```{r}
pw_lm <- lmer(pw ~ condition + (1|prolificPID), data = manipulation_data)
summary(pw_lm)
confint(pw_lm, method = "Wald")
```

Changes in resources
```{r}
rd_lm <- lmer(resources_difference ~ condition + (1|prolificPID), data = manipulation_data)
summary(rd_lm)
confint(rd_lm, method = "Wald")

```

Perceived recovery after break
```{r}
r_lm <- lmer(ra ~ condition + (1|prolificPID), data = manipulation_data)
summary(r_lm) 
confint(r_lm, method = "Wald")
```

Perceived use of new strategies/moves after a break
```{r}
nm_lm <- lmer(perceived_use_of_new_strategies ~ condition + (1|prolificPID), data = manipulation_data)
summary(nm_lm) 
confint(nm_lm, method = "Wald")
```

If Sokoban is a suitable non-routine problem, participants may have insight experiences if they are able to solve the puzzles. They should be more likely to have insight experiences after returning from a break, compared to those that completed the puzzle early.

```{r}
insight_data  <- data %>% 
  drop_na(aha1, aha2, aha3) %>% 
  mutate(
    aha = rowMeans(select(., aha1, aha2, aha3))
  )

i_lm <- lmer(aha ~ completedLevel + completedEarly + (1|prolificPID), data = insight_data)
summary(i_lm) 
confint(i_lm, method = "Wald")
```
Here, we can see participants rated higher insight (3 + 3) if they completed a level. However, if they completed a level early, their rating of perceived insight decreases (3 + 3 - .5).

## Main Analyses

First, we check if any of the control variables are relevant. 

```{r}
main_data <- data %>%
  left_join(
    survey %>%
      select(prolificPID, age, handedness, sex, videoGameHours, smartphoneHours, sokobanFamiliarity, digitalDeviceHours, shortFormVideoHours, trialOrder, conditionOrder),
    by = "prolificPID"
  ) %>%
  filter(
    handedness %in% c("left","right"), # 5 participants put ambidextrous
    completedEarly != 1 # include only those who encountered manipulations
    ) %>%
  mutate(sex = factor(sex, levels = c(0, 1), labels = c("Female", "Male")),)

```

We compare a null model (with random intercepts) to other models. 

```{r warning=FALSE}
model1_null <- glmer(completedLevel ~ (1|prolificPID), family="binomial", control = glmerControl(optimizer = "bobyqa"), data = main_data)

model1_level <- glmer(completedLevel ~ level + (1|prolificPID), family="binomial", control = glmerControl(optimizer = "bobyqa"), data = main_data)

model1_condition<- glmer(completedLevel ~  condition + (1|prolificPID), family="binomial", control = glmerControl(optimizer = "bobyqa"), data = main_data)

model1_base <- glmer(completedLevel ~  level * condition + (1|prolificPID), family="binomial", control = glmerControl(optimizer = "bobyqa"), data = main_data)

model1_noint <- glmer(completedLevel ~ level + condition + (1|prolificPID), family="binomial", control = glmerControl(optimizer = "bobyqa"), data = main_data)

model1_age <- glmer(completedLevel ~  age + (1|prolificPID), family="binomial", control = glmerControl(optimizer = "bobyqa"), data = main_data)

model1_sex <- glmer(completedLevel ~   sex + (1|prolificPID), family="binomial", control = glmerControl(optimizer = "bobyqa"), data = main_data)

model1_handedness <- glmer(completedLevel ~   handedness + (1|prolificPID), family="binomial", control = glmerControl(optimizer = "bobyqa"), data = main_data)

model1_videoGames <- glmer(completedLevel ~   videoGameHours + (1|prolificPID), family="binomial", control = glmerControl(optimizer = "bobyqa"), data = main_data)

model1_smartphones <- glmer(completedLevel ~   smartphoneHours + (1|prolificPID), family="binomial", control = glmerControl(optimizer = "bobyqa"), data = main_data)

model1_sokoban <- glmer(completedLevel ~   sokobanFamiliarity + (1|prolificPID), family="binomial", control = glmerControl(optimizer = "bobyqa"), data = main_data)

model1_digitalDevice <- glmer(completedLevel ~   digitalDeviceHours + (1|prolificPID), family="binomial", control = glmerControl(optimizer = "bobyqa"), data = main_data)

model1_shortFormVideos <- glmer(completedLevel ~   shortFormVideoHours + (1|prolificPID), family="binomial", control = glmerControl(optimizer = "bobyqa"), data = main_data)

model1_trialOrder <- glmer(completedLevel ~   trialOrder + (1|prolificPID), family="binomial", control = glmerControl(optimizer = "bobyqa"), data = main_data)

model1_conditionOrder <- glmer(completedLevel ~  conditionOrder + (1|prolificPID), family="binomial", control = glmerControl(optimizer = "bobyqa"), data = main_data)

models1 <- list(
  null = model1_null,
  level = model1_level,
  condition = model1_condition,
  noint = model1_noint,
  base = model1_base,
  age = model1_age,
  sex = model1_sex,
  handedness = model1_handedness,
  videoGames = model1_videoGames,
  smartphones = model1_smartphones,
  sokoban = model1_sokoban,
  digitalDevice = model1_digitalDevice,
  shortFormVideos = model1_shortFormVideos,
  trialOrder = model1_trialOrder,
  conditionOrder = model1_conditionOrder
)

aic_results1 <- sapply(models1, AIC)
aic_results1 <- sort(aic_results1)
aic_results1

bic_results1 <- sapply(models1, BIC)
bic_results1 <- sort(bic_results1)
bic_results1


```

The model with level as a predictor performs the best. Sex is a relevant covariate that improves the model fit. Most models agree in terms of what variable or interaction is significant. Males seem to perform considerably better than females on solving Sokoban puzzles. 


```{r}
model1_level_sex <- glmer(completedLevel ~  level + sex + (1|prolificPID), family="binomial", control = glmerControl(optimizer = "bobyqa"), data = main_data)

anova(model1_level_sex, model1_level)
```

Our primary model will include only level and sex. 

```{r}
model1_data <- data %>%
  left_join(
    survey %>%
      select(sex, prolificPID),
    by = "prolificPID"
  ) %>%
  filter(
    completedEarly != 1
    ) %>%
  mutate(sex = factor(sex, levels = c(0, 1), labels = c("Female", "Male")),)

model1_final <- glmer(completedLevel ~  level + sex + (1|prolificPID), family="binomial", control = glmerControl(optimizer = "bobyqa"), data = model1_data)

summary(model1_final)
r.squaredGLMM(model1_final, null = model1_null)
confint(model1_final, method = "Wald")
exp(fixef(model1_final))
exp(confint(model1_final, parm = "beta_", method="Wald"))

```

We run a similar set of comparisons for the dependent variable: duration after break (to complete level).

```{r warning = FALSE}
completed_data <- main_data %>%
  filter(completedLevel == 1)

model2_null <- lmer(durationAfterBreak ~ (1|prolificPID), data = completed_data)

model2_condition <- lmer(durationAfterBreak ~   condition + (1|prolificPID), data = completed_data)

model2_level <- lmer(durationAfterBreak ~  level + (1|prolificPID), data = completed_data)

model2_noint <- lmer(durationAfterBreak ~  level + condition + (1|prolificPID), data = completed_data)

model2_base <- lmer(durationAfterBreak ~  level * condition + (1|prolificPID), data = completed_data)

model2_age <- lmer(durationAfterBreak ~  age + (1|prolificPID), data = completed_data)

model2_sex <- lmer(durationAfterBreak ~  sex + (1|prolificPID), data = completed_data)

model2_handedness <- lmer(durationAfterBreak ~   handedness + (1|prolificPID), data = completed_data)

model2_videoGames <- lmer(durationAfterBreak ~ videoGameHours + (1|prolificPID), data = completed_data)

model2_smartphones <- lmer(durationAfterBreak ~   smartphoneHours + (1|prolificPID), data = completed_data)

model2_sokoban <- lmer(durationAfterBreak ~  sokobanFamiliarity + (1|prolificPID), data = completed_data)

model2_digitalDevice <- lmer(durationAfterBreak ~  digitalDeviceHours + (1|prolificPID), data = completed_data)

model2_shortFormVideos <- lmer(durationAfterBreak ~  shortFormVideoHours + (1|prolificPID), data = completed_data)

model2_trialOrder <- lmer(durationAfterBreak ~   trialOrder + (1|prolificPID), data = completed_data)

model2_conditionOrder <- lmer(durationAfterBreak ~   conditionOrder + (1|prolificPID), data = completed_data)

models2 <- list(
  null = model2_null,
  condition = model2_condition,
  level = model2_level,
  noint = model2_noint,
  base = model2_base,
  age = model2_age,
  sex = model2_sex,
  handedness = model2_handedness,
  videoGames = model2_videoGames,
  smartphones = model2_smartphones,
  sokoban = model2_sokoban,
  digitalDevice = model2_digitalDevice,
  shortFormVideos = model2_shortFormVideos,
  trialOrder = model2_trialOrder,
  conditionOrder = model2_conditionOrder
)

# Comparing Models
aic_results2 <- sapply(models2, AIC)
aic_results2 <- sort(aic_results2)
aic_results2

bic_results2 <- sapply(models2, BIC)
bic_results2 <- sort(bic_results2)
bic_results2
```

Level and condition, along with their interaction, is the best fitting model. Trial and condition order seem like relevant covariates.

```{r}
model2_trialOrder_base <- lmer(durationAfterBreak ~  level * condition + trialOrder + (1|prolificPID), data = completed_data)
model2_conditionOrder_base <- lmer(durationAfterBreak ~  level * condition + conditionOrder + (1|prolificPID), data = completed_data)

anova(model2_trialOrder_base, model2_base)
anova(model2_conditionOrder_base, model2_base)

```

Comparing models using maximum likelihood generally favor the base model. 

```{r}
model2_data <- data %>%
  left_join(
    survey %>%
      select(prolificPID),
    by = "prolificPID"
  ) %>% 
  filter(completedLevel == 1)
  
model2_final <- lmer(durationAfterBreak ~  level * condition + (1|prolificPID), data = model2_data)

summary(model2_final)
r.squaredGLMM(model2_final, null = model2_base)
confint(model2_final, method = "Wald")

```
Here we explore contrasts in each level. 

```{r, warning = FALSE}

emm2 <- emmeans(model2_final, ~ condition | level)
pairs(emm2, adjust = "none")
eff_size(emm2, sigma = sigma(model2_final), edf = df.residual(model2_final))

```

A simple plot. 
```{r}

preds1 <- ggpredict(model2_final, terms = c("level", "condition"))
plot1 <- ggplot(preds1, aes(x = group, y = predicted)) +
  geom_point(size = 2.5) +
  geom_errorbar(
    aes(ymin = conf.low, ymax = conf.high),
    width = 0.15,
    linewidth = 0.6
  ) +
  facet_wrap(~ x, nrow = 1) +
  labs(
    x = "",
    y = "Duration (s)"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    panel.grid = element_blank(),        
    strip.text = element_text(face = "bold"),
    axis.line = element_line(linewidth = 0.6, color = "black"),  
    axis.ticks = element_line(linewidth = 0.6)
  )

ggsave(
  filename = "solutionTime.pdf",
  plot = plot1,
  width = 7,
  height = 3,
  units = "in"
)

plot1
```

## Clustering Analysis

We have a lot of data on the exact moves participants used while working on the puzzles. We can see how strategies shift when participants are interrupted to take a break. We can use clustering in order to cluster strategies by comparing move set similarity in each level. First, we use every participants' move sets to build a list of every move set made.


```{r}
data$allMovesets <- Map(c, data$beforeBreakMovesets, data$afterBreakMovesets)

get_cleaned_movesets <- function(level_name) {
  level_rows <- data[data$level == level_name, ]
  combined_movesets <- unlist(level_rows$allMovesets, use.names = FALSE)
  filtered <- combined_movesets[nchar(combined_movesets) >= 4]
  unique(filtered)
}

easy_movesets   <- get_cleaned_movesets("easy")
medium_movesets <- get_cleaned_movesets("medium")
hard_movesets   <- get_cleaned_movesets("hard")

```

For the hard level, there are groups of moves that always occur together. To better identify strategies, we convert these patterns of moves.

```{r}
hard_movesets <- gsub("rrddllu", "z", hard_movesets)
hard_movesets <- gsub("drruull", "x", hard_movesets)
```

Move sets will be considered similar if they have similar prefixes. For example, lrlrudud would be similar to lrluduu. The more prefixes they have in common, the more likely they are to be similar strategies in Sokoban. We compute a distance matrix for each level.

```{r}
prefix_distance <- function(a, b) {
  min_len <- min(nchar(a), nchar(b))
  match_length <- 0
  for (i in seq_len(min_len)) {
    if (substr(a, i, i) != substr(b, i, i)) break
    match_length <- match_length + 1
  }
  return(1 - (match_length / min_len))
}

build_prefix_dist_matrix <- function(movesets) {
  n <- length(movesets)
  dist_mat <- matrix(0, n, n)
  
  for (i in 1:(n-1)) {
    for (j in (i+1):n) {
      d <- prefix_distance(movesets[i], movesets[j])
      dist_mat[i, j] <- d
      dist_mat[j, i] <- d 
    }
  }
  
  as.dist(dist_mat) 
}

easy_dist <- build_prefix_dist_matrix(easy_movesets)
medium_dist <- build_prefix_dist_matrix(medium_movesets)
hard_dist <- build_prefix_dist_matrix(hard_movesets)

easy_clust <- hclust(easy_dist, method = "complete")
medium_clust <- hclust(medium_dist, method = "complete")
hard_clust <- hclust(hard_dist, method = "complete")

```

We use silhouette analysis to determine the optimal number of clusters.

Easy Level
```{r}

avg_sil <- sapply(5:30, function(k) {
  clusters <- cutree(easy_clust, k)
  sil <- silhouette(clusters, easy_dist)
  mean(sil[, 3])  
})

plot(5:30, avg_sil, type = "b",
     xlab = "Number of clusters", ylab = "Average silhouette width")


```

Medium Level
```{r}
avg_sil <- sapply(5:30, function(k) {
  clusters <- cutree(medium_clust, k)
  sil <- silhouette(clusters, medium_dist)
  mean(sil[, 3])  
})

plot(5:30, avg_sil, type = "b",
     xlab = "Number of clusters", ylab = "Average silhouette width")

```

Hard Level
```{r}
avg_sil <- sapply(5:30, function(k) {
  clusters <- cutree(hard_clust, k)
  sil <- silhouette(clusters, hard_dist)
  mean(sil[, 3])  
})

plot(5:30, avg_sil, type = "b",
     xlab = "Number of clusters", ylab = "Average silhouette width")

```

Based on the plots, the number of clusters for the easy, medium, and hard puzzles will be 12, 17, and 11, respectively. Using slightly different numbers of clusters results in similar results. 

```{r}
clusters_easy <- cutree(easy_clust, k = 12)
clusters_medium <- cutree(medium_clust, k = 17)
clusters_hard <- cutree(hard_clust, k = 11)
```

We generate new data columns which show the cluster number rather than the string of moves. A very few number of participants did not have move sets before or after break and are removed from this analysis.


```{r}
main_data$beforeBreakMovesets <- mapply(function(moves, level) {
  moves <- moves[nchar(moves) >= 4]
  if (level == "hard") {
    moves <- gsub("rrddllu", "z", moves)
    moves <- gsub("drruull", "x", moves)
  }
  return(moves)
}, main_data$beforeBreakMovesets, main_data$level, SIMPLIFY = FALSE)

main_data$afterBreakMovesets <- mapply(function(moves, level) {
  moves <- moves[nchar(moves) >= 4]
  if (level == "hard") {
    moves <- gsub("rrddllu", "z", moves)
    moves <- gsub("drruull", "x", moves)
  }
  return(moves)
}, main_data$afterBreakMovesets, main_data$level, SIMPLIFY = FALSE)
moveset_data <- main_data[
  lengths(main_data$beforeBreakMovesets) > 0 & 
  lengths(main_data$afterBreakMovesets) > 0, 
]

lookup_easy <- setNames(clusters_easy, easy_movesets)
lookup_medium <- setNames(clusters_medium, medium_movesets)
lookup_hard <- setNames(clusters_hard, hard_movesets)

map_moves_to_clusters <- function(moves, level) {
  level <- as.character(level)
  lookup <- switch(level,
                   "easy" = lookup_easy,
                   "medium" = lookup_medium,
                   "hard" = lookup_hard)
  
  sapply(moves, function(m) lookup[[m]], USE.NAMES = FALSE)
}

moveset_data$beforeClusters <- mapply(map_moves_to_clusters,
                                   moveset_data$beforeBreakMovesets,
                                   moveset_data$level,
                                   SIMPLIFY = FALSE)

moveset_data$afterClusters <- mapply(map_moves_to_clusters,
                                  moveset_data$afterBreakMovesets,
                                  moveset_data$level,
                                  SIMPLIFY = FALSE)

```

We now create a column which displays whether an individual's first move when returning to the problem after a break is a new strategy (new cluster) or a variation/copy of a previous strategy. 

We also count the number of moves made before the break for use as a control variable, since using a new strategy is more likely if you have less moves made before the break.

```{r}

moveset_data$newMove <- mapply(function(before, after) {
  first_after <- after[1]
  if (first_after %in% before) 0 else 1
}, moveset_data$beforeClusters, moveset_data$afterClusters) 

moveset_data$beforeBreakLength <- sapply(moveset_data$beforeBreakMovesets, length)

```

Let's check whether different conditions or levels predict the use of new moves. 

```{r}
model3_null <- glmer(newMove ~  (1|prolificPID), family="binomial", control = glmerControl(optimizer = "bobyqa"), data = moveset_data)
model3_base <- glmer(newMove ~  level * condition + beforeBreakLength + (1|prolificPID), family="binomial", control = glmerControl(optimizer = "bobyqa"), data = moveset_data)

summary(model3_base)
r.squaredGLMM(model3_base, null = model3_null)
confint(model3_base, method = "Wald")
exp(fixef(model3_base))
exp(confint(model3_base, parm = "beta_", method="Wald"))
```

Pairwise contrasts. 
```{r}
emmeans(model3_base, ~ condition | level, type = "response") %>%
    pairs(adjust="none")
```

Simple plot.
```{r}
preds2 <- ggpredict(model3_base, terms = c("level", "condition"))
plot2 <- ggplot(preds2, aes(x = group, y = predicted)) +
  geom_point(size = 2.5) +
  geom_errorbar(
    aes(ymin = conf.low, ymax = conf.high),
    width = 0.15,
    linewidth = 0.6
  ) +
  facet_wrap(~ x, nrow = 1) +
  labs(
    x = "",
    y = "New Strategy Likelihood (%)"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    panel.grid = element_blank(),         
    strip.text = element_text(face = "bold"),
    axis.line = element_line(linewidth = 0.6, color = "black"),  
    axis.ticks = element_line(linewidth = 0.6)
  )

ggsave(
  filename = "newMove.pdf",
  plot = plot2,
  width = 7,
  height = 3,
  units = "in"
)

plot2
```

